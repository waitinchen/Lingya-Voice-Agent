/**
 * Cartesia èªéŸ³åˆæˆæ¨¡çµ„ï¼ˆå®˜æ–¹ SDK ç‰ˆæœ¬ï¼‰
 * Step â‘¡-Bï¼šå‡ç´šç‚º Cartesia è²ç·šè¦ºé†’ç‰ˆ
 * ä½¿ç”¨ @cartesia/cartesia-js å®˜æ–¹ SDK
 */

import fs from "fs";
import path from "path";
import dotenv from "dotenv";
import { CartesiaClient } from "@cartesia/cartesia-js";
import { mergeVoiceParams, getVoiceParamsDescription } from "./voice-params.js";

dotenv.config();

const client = new CartesiaClient({
  apiKey: process.env.CARTESIA_API_KEY,
});

/**
 * ä½¿ç”¨ Cartesia å®˜æ–¹ SDK å°‡æ–‡å­—è½‰æ›ç‚ºèªéŸ³ï¼ˆæ”¯æŒæƒ…ç·’æ¨™ç±¤ï¼‰
 * @param {string} text - è¦åˆæˆçš„æ–‡å­—
 * @param {string} outputPath - è¼¸å‡ºéŸ³æª”è·¯å¾‘ï¼ˆå¯é¸ï¼‰
 * @param {Object} options - é¸é …
 * @param {Array<string>} options.tags - æƒ…ç·’æ¨™ç±¤åˆ—è¡¨
 * @param {string} options.emotion - èˆŠç‰ˆæƒ…ç·’åƒæ•¸ï¼ˆå‘å¾Œå…¼å®¹ï¼‰
 * @returns {Promise<string|null>} - æˆåŠŸè¿”å›æª”æ¡ˆè·¯å¾‘ï¼Œå¤±æ•—è¿”å› null
 */
export async function synthesizeSpeechCartesia(
  text,
  outputPath = null,
  options = {}
) {
  try {
    const { tags = [], emotion } = options;
    
    // å°å…¥æƒ…ç·’è™•ç†æ¨¡çµ„
    const { applyEmotion } = await import("../helpers/emotion.js");
    
    // å¦‚æœæœ‰èˆŠç‰ˆ emotion åƒæ•¸ï¼Œè½‰æ›ç‚º tagsï¼ˆå‘å¾Œå…¼å®¹ï¼‰
    let finalTags = [...tags];
    if (emotion && !tags.length) {
      const emotionToTag = {
        'é–‹å¿ƒ': ['excited', 'smile'],
        'é›£é': ['softer', 'breathy'],
        'ç”Ÿæ°£': ['angry', 'louder'],
        'å¹³éœ': ['neutral'],
      };
      if (emotionToTag[emotion]) {
        finalTags = emotionToTag[emotion];
      }
    }
    
    // æ‡‰ç”¨æƒ…ç·’æ¨™ç±¤ï¼ˆæ–‡å­—å±¤è™•ç†ï¼‰
    const { script, speed, volume } = applyEmotion({
      text,
      tags: finalTags,
    });

    // ========================================
    // ğŸ©µ èªæ°£æ¨™ç±¤è½‰è­¯å±¤ï¼šè¨ˆç®—è²éŸ³åƒæ•¸
    // ========================================
    const voiceParams = mergeVoiceParams(finalTags);

    // å¦‚æœæ²’æœ‰æŒ‡å®šè¼¸å‡ºè·¯å¾‘ï¼Œä½¿ç”¨é»˜èªè·¯å¾‘
    if (!outputPath) {
      const timestamp = Date.now();
      outputPath = path.join(process.cwd(), "outputs", `soft-cartesia-${timestamp}.wav`);
    }

    // ç¢ºä¿ outputs ç›®éŒ„å­˜åœ¨
    const outputDir = path.dirname(outputPath);
    if (!fs.existsSync(outputDir)) {
      fs.mkdirSync(outputDir, { recursive: true });
    }

    console.log(`ğŸ™ï¸ å‘¼å« Cartesia TTS`);
    console.log(`   æ¨™ç±¤: [${finalTags.join(", ") || "ç„¡"}]`);
    console.log(`   ${getVoiceParamsDescription(finalTags)}`);

    // æ§‹å»ºè«‹æ±‚åƒæ•¸
    const requestParams = {
      modelId: process.env.CARTESIA_TTS_MODEL_ID || "sonic-3",
      transcript: script, // ä½¿ç”¨è™•ç†å¾Œçš„æ–‡å­—
      voice: {
        mode: "id",
        id: process.env.CARTESIA_VOICE_ID,
      },
      language: process.env.CARTESIA_LANGUAGE || "zh",
      outputFormat: {
        container: "wav",
        sampleRate: parseInt(process.env.CARTESIA_SAMPLE_RATE) || 44100,
        encoding: "pcm_s16le",
      },
      save: true,
    };
    
    // å¦‚æœ Cartesia SDK æ”¯æŒ voice settingsï¼ŒåŠ å…¥è²éŸ³åƒæ•¸
    if (voiceParams.appliedTags.length > 0) {
      console.log(`   ğŸ’¡ è²éŸ³å±¤åƒæ•¸å·²è¨ˆç®—ï¼ˆpitch=${voiceParams.pitch.toFixed(2)}, rate=${voiceParams.rate.toFixed(2)}, volume=${voiceParams.volume.toFixed(2)}ï¼‰ï¼Œå¾… Cartesia API æ”¯æŒæ™‚è‡ªå‹•æ‡‰ç”¨`);
    }
    
    const response = await client.tts.bytes(requestParams);

    // è™•ç†éŸ¿æ‡‰ï¼šSDK è¿”å›çš„å¯èƒ½æ˜¯æµï¼ˆStreamï¼‰
    let audioBuffer;
    if (Buffer.isBuffer(response)) {
      audioBuffer = response;
    } else if (response instanceof Uint8Array) {
      audioBuffer = Buffer.from(response);
    } else if (typeof response.getReader === 'function' || response[Symbol.asyncIterator]) {
      // è™•ç†æµï¼ˆStreamï¼‰
      const chunks = [];
      for await (const chunk of response) {
        chunks.push(chunk);
      }
      audioBuffer = Buffer.concat(chunks);
    } else if (response.arrayBuffer) {
      audioBuffer = Buffer.from(await response.arrayBuffer());
    } else {
      // å˜—è©¦å°‡æµè½‰æ›ç‚º Buffer
      const chunks = [];
      const reader = response.getReader();
      try {
        while (true) {
          const { done, value } = await reader.read();
          if (done) break;
          chunks.push(value);
        }
        audioBuffer = Buffer.concat(chunks);
      } finally {
        reader.releaseLock();
      }
    }
    
    fs.writeFileSync(outputPath, audioBuffer);

    console.log("âœ… èªéŸ³æª”æ¡ˆç”Ÿæˆï¼š", outputPath);
    return outputPath;
  } catch (err) {
    console.error("âŒ Cartesia TTS éŒ¯èª¤ï¼š", err.message);
    if (err.response) {
      console.error("   éŒ¯èª¤è©³æƒ…:", err.response);
    }
    return null;
  }
}

/**
 * ä½¿ç”¨ Cartesia å®˜æ–¹ SDK å°‡æ–‡å­—è½‰æ›ç‚ºèªéŸ³ Bufferï¼ˆæ”¯æŒæƒ…ç·’æ¨™ç±¤ï¼‰
 * @param {string} text - è¦åˆæˆçš„æ–‡å­—
 * @param {Object} options - é¸é …
 * @param {Array<string>} options.tags - æƒ…ç·’æ¨™ç±¤åˆ—è¡¨ï¼ˆwhisper, breathy, excited, angry, smile, fast, slow, louder, quieter, pause-XXX ç­‰ï¼‰
 * @param {string} options.emotion - èˆŠç‰ˆæƒ…ç·’åƒæ•¸ï¼ˆå‘å¾Œå…¼å®¹ï¼‰
 * @returns {Promise<Buffer|null>} - æˆåŠŸè¿”å›éŸ³é » Bufferï¼Œå¤±æ•—è¿”å› null
 */
export async function synthesizeSpeechCartesiaToBuffer(text, options = {}) {
  try {
    const { tags = [], emotion } = options;
    
    // å°å…¥æƒ…ç·’è™•ç†æ¨¡çµ„
    const { applyEmotion } = await import("../helpers/emotion.js");
    
    // å¦‚æœæœ‰èˆŠç‰ˆ emotion åƒæ•¸ï¼Œè½‰æ›ç‚º tagsï¼ˆå‘å¾Œå…¼å®¹ï¼‰
    let finalTags = [...tags];
    if (emotion && !tags.length) {
      const emotionToTag = {
        'é–‹å¿ƒ': ['excited', 'smile'],
        'é›£é': ['softer', 'breathy'],
        'ç”Ÿæ°£': ['angry', 'louder'],
        'å¹³éœ': ['neutral'],
      };
      if (emotionToTag[emotion]) {
        finalTags = emotionToTag[emotion];
      }
    }
    
    // æ‡‰ç”¨æƒ…ç·’æ¨™ç±¤ï¼ˆæ–‡å­—å±¤è™•ç†ï¼‰
    const { script, speed, volume, sfx, pauses } = applyEmotion({
      text,
      tags: finalTags,
    });
    
    // ========================================
    // ğŸ©µ èªæ°£æ¨™ç±¤è½‰è­¯å±¤ï¼šè¨ˆç®—è²éŸ³åƒæ•¸
    // ========================================
    const voiceParams = mergeVoiceParams(finalTags);
    
    console.log(`ğŸ™ï¸ å‘¼å« Cartesia TTS`);
    console.log(`   æ¨™ç±¤: [${finalTags.join(", ") || "ç„¡"}]`);
    console.log(`   æ–‡å­—å±¤åƒæ•¸: speed=${speed.toFixed(2)}, volume=${volume.toFixed(2)}`);
    console.log(`   ${getVoiceParamsDescription(finalTags)}`);
    
    // æ§‹å»ºè«‹æ±‚åƒæ•¸
    const requestParams = {
      modelId: process.env.CARTESIA_TTS_MODEL_ID || "sonic-3",
      transcript: script, // ä½¿ç”¨è™•ç†å¾Œçš„æ–‡å­—ï¼ˆå¯èƒ½åŒ…å« textCuesï¼‰
      voice: {
        mode: "id",
        id: process.env.CARTESIA_VOICE_ID,
      },
      language: process.env.CARTESIA_LANGUAGE || "zh",
      outputFormat: {
        container: "wav",
        sampleRate: parseInt(process.env.CARTESIA_SAMPLE_RATE) || 44100,
        encoding: "pcm_s16le",
      },
      save: false, // Buffer æ¨¡å¼ä¸éœ€è¦ä¿å­˜æª”æ¡ˆ
    };
    
    // å¦‚æœ Cartesia SDK æ”¯æŒ voice settings æˆ– generation configï¼ŒåŠ å…¥è²éŸ³åƒæ•¸
    // æ³¨æ„ï¼šç•¶å‰ Cartesia API å¯èƒ½ä¸æ”¯æŒé€™äº›åƒæ•¸ï¼Œä½†æˆ‘å€‘å…ˆæº–å‚™å¥½æ¥å£
    // æœªä¾†å¦‚æœæ”¯æŒï¼Œå¯ä»¥é€™æ¨£å‚³éï¼š
    // if (client.tts.bytes.supportsVoiceParams) {
    //   requestParams.voiceSettings = {
    //     pitch: voiceParams.pitch,
    //     rate: voiceParams.rate,
    //     volume: voiceParams.volume,
    //   };
    // }
    
    // ç›®å‰å…ˆè¨˜éŒ„åƒæ•¸ï¼Œç”¨æ–¼èª¿è©¦å’Œæœªä¾†æ“´å±•
    if (voiceParams.appliedTags.length > 0) {
      console.log(`   ğŸ’¡ è²éŸ³å±¤åƒæ•¸å·²è¨ˆç®—ï¼ˆpitch=${voiceParams.pitch.toFixed(2)}, rate=${voiceParams.rate.toFixed(2)}, volume=${voiceParams.volume.toFixed(2)}ï¼‰ï¼Œå¾… Cartesia API æ”¯æŒæ™‚è‡ªå‹•æ‡‰ç”¨`);
    }
    
    const response = await client.tts.bytes(requestParams);

    // è™•ç†éŸ¿æ‡‰ï¼šSDK è¿”å›çš„å¯èƒ½æ˜¯æµï¼ˆStreamï¼‰
    let audioBuffer;
    if (Buffer.isBuffer(response)) {
      audioBuffer = response;
    } else if (response instanceof Uint8Array) {
      audioBuffer = Buffer.from(response);
    } else if (typeof response.getReader === 'function' || response[Symbol.asyncIterator]) {
      // è™•ç†æµï¼ˆStreamï¼‰
      const chunks = [];
      for await (const chunk of response) {
        chunks.push(chunk);
      }
      audioBuffer = Buffer.concat(chunks);
    } else if (response.arrayBuffer) {
      audioBuffer = Buffer.from(await response.arrayBuffer());
    } else {
      // å˜—è©¦å°‡æµè½‰æ›ç‚º Buffer
      const chunks = [];
      const reader = response.getReader();
      try {
        while (true) {
          const { done, value } = await reader.read();
          if (done) break;
          chunks.push(value);
        }
        audioBuffer = Buffer.concat(chunks);
      } finally {
        reader.releaseLock();
      }
    }
    
    return audioBuffer;
  } catch (err) {
    console.error("âŒ Cartesia TTS éŒ¯èª¤ï¼š", err.message);
    if (err.response) {
      console.error("   éŒ¯èª¤è©³æƒ…:", err.response);
    }
    return null;
  }
}
