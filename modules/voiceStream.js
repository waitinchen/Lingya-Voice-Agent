/**
 * å³æ™‚èªéŸ³æµè™•ç†æ¨¡çµ„
 * è™•ç† WebRTC æˆ– WebSocket èªéŸ³ä¸²æµ
 */

import { config } from '../config/config.js';
import { transcribe } from './whisper.js';
import { generateResponse, analyzeEmotion } from './llm.js';
import { synthesize } from './tts.js';

/**
 * è™•ç†èªéŸ³æµä¸¦è¿”å›å›æ‡‰
 * @param {Buffer|ArrayBuffer} audioChunk - éŸ³é »ç‰‡æ®µ
 * @param {Object} context - å°è©±ä¸Šä¸‹æ–‡
 * @returns {Promise<Object>} åŒ…å«å›æ‡‰éŸ³é »å’Œæ–‡å­—çš„ç‰©ä»¶
 */
export async function processVoiceStream(audioChunk, context = {}) {
  try {
    // 1. èªéŸ³è­˜åˆ¥ (STT)
    console.log('ğŸ¤ æ­£åœ¨è­˜åˆ¥èªéŸ³...');
    const transcribedText = await transcribe(audioChunk, {
      language: context.language || 'zh',
    });

    if (!transcribedText || transcribedText.trim().length === 0) {
      return {
        text: '',
        audio: null,
        error: 'æœªè­˜åˆ¥åˆ°èªéŸ³',
      };
    }

    console.log(`ğŸ“ è­˜åˆ¥çµæœ: ${transcribedText}`);

    // 2. åˆ†ææƒ…ç·’
    const emotion = await analyzeEmotion(transcribedText);
    console.log(`ğŸ˜Š æª¢æ¸¬æƒ…ç·’: ${emotion}`);

    // 3. LLM ç”Ÿæˆå›æ‡‰
    console.log('ğŸ¤– æ­£åœ¨ç”Ÿæˆå›æ‡‰...');
    const conversationHistory = context.history || [];
    const responseText = await generateResponse(
      transcribedText,
      conversationHistory,
      {
        emotion,
        tone: context.tone || 'è‡ªç„¶',
        temperature: context.temperature || 0.7,
      }
    );

    console.log(`ğŸ’¬ AI å›æ‡‰: ${responseText}`);

    // 4. èªéŸ³åˆæˆ (TTS)
    console.log('ğŸ”Š æ­£åœ¨åˆæˆèªéŸ³...');
    const audioResponse = await synthesize(responseText, {
      emotion,
      lang: context.language || 'zh',
    });

    // 5. æ›´æ–°å°è©±æ­·å²
    const updatedHistory = [
      ...conversationHistory,
      { role: 'user', content: transcribedText },
      { role: 'assistant', content: responseText },
    ];

    return {
      text: responseText,
      audio: audioResponse,
      emotion,
      history: updatedHistory,
    };
  } catch (error) {
    console.error('âŒ èªéŸ³æµè™•ç†å¤±æ•—:', error);
    return {
      text: '',
      audio: null,
      error: error.message,
    };
  }
}

/**
 * è™•ç†é€£çºŒèªéŸ³æµï¼ˆç”¨æ–¼å¯¦æ™‚å°è©±ï¼‰
 */
export class VoiceStreamProcessor {
  constructor() {
    this.conversationHistory = [];
    this.currentEmotion = 'å¹³éœ';
  }

  /**
   * è™•ç†æ–°çš„éŸ³é »ç‰‡æ®µ
   */
  async processChunk(audioChunk, options = {}) {
    const result = await processVoiceStream(audioChunk, {
      history: this.conversationHistory,
      emotion: this.currentEmotion,
      ...options,
    });

    // æ›´æ–°ç‹€æ…‹
    if (result.history) {
      this.conversationHistory = result.history;
    }
    if (result.emotion) {
      this.currentEmotion = result.emotion;
    }

    return result;
  }

  /**
   * é‡ç½®å°è©±æ­·å²
   */
  reset() {
    this.conversationHistory = [];
    this.currentEmotion = 'å¹³éœ';
  }

  /**
   * ç²å–ç•¶å‰å°è©±ç‹€æ…‹
   */
  getState() {
    return {
      history: this.conversationHistory,
      emotion: this.currentEmotion,
    };
  }
}

