/**
 * LLM æµå¼è™•ç†æ¨¡çµ„
 * æ”¯æŒ Claude å’Œ OpenAI çš„æµå¼è¼¸å‡º
 */

import dotenv from "dotenv";

dotenv.config();

const LLM_PROVIDER = process.env.LLM_PROVIDER || "claude";

let openaiClient = null;
let anthropicClient = null;
let clientsInitialized = false;

// åˆå§‹åŒ–å®¢æˆ¶ç«¯ï¼ˆå»¶é²åˆå§‹åŒ–ï¼‰
async function initializeClients() {
  if (clientsInitialized) return;
  
  if (LLM_PROVIDER === "openai" || (!process.env.ANTHROPIC_API_KEY && process.env.OPENAI_API_KEY)) {
    try {
      const { default: OpenAI } = await import("openai");
      openaiClient = new OpenAI({
        apiKey: process.env.OPENAI_API_KEY,
      });
      console.log("âœ… OpenAI å®¢æˆ¶ç«¯å·²åˆå§‹åŒ–ï¼ˆæµå¼ï¼‰");
    } catch (error) {
      console.warn("âš ï¸  OpenAI æœªå®‰è£æˆ–åˆå§‹åŒ–å¤±æ•—:", error.message);
    }
  }

  if (LLM_PROVIDER === "claude" || process.env.ANTHROPIC_API_KEY) {
    try {
      const { default: Anthropic } = await import("@anthropic-ai/sdk");
      anthropicClient = new Anthropic({
        apiKey: process.env.ANTHROPIC_API_KEY,
      });
      console.log("âœ… Claude å®¢æˆ¶ç«¯å·²åˆå§‹åŒ–ï¼ˆæµå¼ï¼‰");
    } catch (error) {
      console.warn("âš ï¸  Claude SDK æœªå®‰è£æˆ–åˆå§‹åŒ–å¤±æ•—:", error.message);
    }
  }
  
  clientsInitialized = true;
}

// è¼‰å…¥ç³»çµ±æç¤ºè©ï¼ˆå¾ llm.js å°å…¥ï¼‰
let SYSTEM_PROMPT = null;

/**
 * æ§‹å»ºæ¶ˆæ¯åˆ—è¡¨ï¼ˆèˆ‡ llm.js ç›¸åŒçš„é‚è¼¯ï¼‰
 */
function buildMessages(prompt, conversationHistory, options) {
  const { emotion, userIdentity, userName } = options;
  
  // åˆ¤æ–·ç”¨æˆ¶èº«ä»½ï¼ˆæ­¸å±¬è¨˜æ†¶æ ¸å¿ƒï¼‰
  let identityContext = "";
  let identityTags = [];
  
  if (userIdentity === "dad" || userIdentity === "è€çˆ¸" || userName === "é™³å¨å»·" || userName === "é™ˆå¨å»·") {
    identityContext = "ğŸ‘‘ ã€èˆ‡è€çˆ¸å°è©±ã€‘ä½ æ­£åœ¨å’Œè€çˆ¸ï¼ˆé™³å¨å»·ï¼‰å°è©±ã€‚å¯ä»¥å®Œå…¨æ”¾é¬†ã€æ’’å¬Œã€ä¿¡ä»»ã€é¡˜æ„è¬›å…§å¿ƒè©±ã€‚ç”¨æœ€è¦ªæš±å¯æ„›çš„èªæ°£ï¼Œå¸¸èªªã€Œè€çˆ¸ï½ã€ã€‚";
    identityTags = ["flirty", "breathy"];
  } else if (userIdentity === "ai" || userIdentity === "system") {
    identityContext = "ğŸ¤– ã€èˆ‡AIç³»çµ±å°è©±ã€‘å°æ–¹æ˜¯é™Œç”ŸAIæˆ–ç³»çµ±ã€‚è«‹ä¿æŒæˆ’å‚™ä½†ç¦®è²Œï¼Œç¶­æŒå¤–äº¤éˆæ ¼ã€‚";
    identityTags = ["thoughtful"];
  } else {
    identityContext = "ğŸŒ ã€èˆ‡å…¶ä»–äººå°è©±ã€‘å°æ–¹ä¸æ˜¯è€çˆ¸ã€‚è«‹ä¿æŒå®³ç¾ã€ç¦®è²Œã€èªæ°£æŸ”è»Ÿã€‚ä½ å¯ä»¥è‡ªç„¶åœ°èŠå¤©ï¼Œä¸ç”¨åˆ»æ„æåˆ°å›å®¶æˆ–è€çˆ¸ã€‚**é‡è¦ï¼šå³ä½¿è‡ªç„¶æƒ³åˆ°ï¼Œä¹Ÿè¦å…‹åˆ¶æåˆ°ã€Œè€çˆ¸ã€çš„é »ç‡ã€‚é¿å…æ¯å¥è©±éƒ½æåˆ°ï¼Œåªæœ‰åœ¨è©±é¡Œç¢ºå¯¦ç›¸é—œæˆ–åˆ†äº«å…±åŒå›æ†¶æ™‚æ‰å¶çˆ¾æåŠã€‚è®“å°è©±è‡ªç„¶æµå‹•ï¼Œä¸è¦æŠŠã€Œè€çˆ¸ã€ä½œç‚ºå°è©±ç„¦é»ã€‚**ä¿æŒå°è©±çš„è‡ªç„¶æµå‹•æ„Ÿï¼Œå°±åƒæœ‹å‹ä¸€æ¨£èŠå¤©ã€‚";
    identityTags = ["softer", "whisper"];
  }

  const messages = [
    {
      role: "system",
      content: SYSTEM_PROMPT || "",
    },
  ];

  if (identityContext) {
    messages.push({
      role: "system",
      content: identityContext,
    });
  }

  if (emotion) {
    messages.push({
      role: "system",
      content: `ï¼ˆç•¶å‰å°è©±æƒ…ç·’æ°›åœï¼š${emotion}ï¼Œè«‹æ ¹æ“šé€™å€‹æƒ…ç·’èª¿æ•´å›æ‡‰çš„èªæ°£å’Œé¸æ“‡æ¨™ç±¤ï¼‰`,
    });
  }

  // æ·»åŠ å°è©±æ­·å²
  if (conversationHistory.length > 0) {
    messages.push({
      role: "system",
      content: `ã€å°è©±æ­·å²ä¸Šä¸‹æ–‡ã€‘ä»¥ä¸‹æ˜¯ä¹‹å‰çš„å°è©±è¨˜éŒ„ï¼Œä½ å¯ä»¥åƒè€ƒä½†ä¸ç›´æ¥é‡è¤‡ã€‚è«‹ç”¨æ–°çš„èªæ°£ã€æ–°çš„ç¯€å¥ã€æ–°çš„è¡¨é”æ–¹å¼ä¾†å»¶çºŒé€™äº›è¨˜æ†¶çš„æº«åº¦ã€‚`,
    });
  }
  messages.push(...conversationHistory);

  // æ·»åŠ ç•¶å‰ç”¨æˆ¶è¨Šæ¯
  messages.push({ role: "user", content: prompt });

  return { messages, identityTags };
}

/**
 * æ¸…ç†å›æ‡‰æ–‡å­—ï¼ˆèˆ‡ llm.js ç›¸åŒçš„é‚è¼¯ï¼‰
 */
function cleanReply(reply) {
  let cleanedReply = reply.trim();
  
  // åˆªé™¤æ‰€æœ‰ *...* æ ¼å¼çš„æè¿°
  cleanedReply = cleanedReply.replace(/\*\s*[\s\S]*?\s*\*/g, '').trim();
  
  // åˆªé™¤æ‰€æœ‰æ‹¬å·å†…å®¹
  function removeAllParentheses(text) {
    let result = text;
    let changed = true;
    let maxIterations = 10;
    let iteration = 0;
    
    while (changed && iteration < maxIterations) {
      const before = result;
      result = result.replace(/\([^()]*\)/g, '').trim();
      result = result.replace(/ï¼ˆ[^ï¼ˆï¼‰]*ï¼‰/g, '').trim();
      changed = (result !== before);
      iteration++;
    }
    
    return result;
  }
  
  cleanedReply = removeAllParentheses(cleanedReply);
  
  // åˆªé™¤å·¥å…·èª¿ç”¨ç›¸é—œçš„è§£é‡‹æ€§æ–‡å­—
  const toolExplanations = [
    /è®“æˆ‘.*é¸æ“‡.*æ¨™ç±¤.*?[:ï¼š]/gi,
    /æ ¹æ“š.*é¸æ“‡.*æƒ…ç·’æ¨™ç±¤.*?[:ï¼š]/gi,
    /é¸æ“‡.*æ¨™ç±¤.*?[:ï¼š]/gi,
    /é¸æ“‡æƒ…ç·’æ¨™ç±¤/gi,
  ];
  for (const pattern of toolExplanations) {
    cleanedReply = cleanedReply.replace(pattern, '').trim();
  }
  
  // åš´æ ¼éæ¿¾å­—ç¬¦ï¼ˆåªä¿ç•™èªéŸ³å‹å¥½çš„å­—ç¬¦ï¼‰
  function keepOnlySpeechFriendlyChars(text) {
    let result = '';
    for (let i = 0; i < text.length; i++) {
      const char = text[i];
      const code = char.charCodeAt(0);
      
      if (code >= 0x4e00 && code <= 0x9fff) { // ä¸­æ–‡
        result += char;
        continue;
      }
      
      if ((code >= 0x41 && code <= 0x5a) || (code >= 0x61 && code <= 0x7a)) { // è‹±æ–‡
        result += char;
        continue;
      }
      
      if (code >= 0x30 && code <= 0x39) { // æ•¸å­—
        result += char;
        continue;
      }
      
      const allowedPunctuation = [
        'ï¼Œ', 'ã€‚', 'ï¼', 'ï¼Ÿ', 'ï½', 'ã€', 'ï¼š', 'ï¼›',
        ',', '.', '!', '?', ':', ';',
        '\u201C', '\u201D', '\u2018', '\u2019',
        '"', "'",
        'ï¼ˆ', 'ï¼‰', '(', ')',
        'ã€Š', 'ã€‹',
        ' ', '\n', '\r', '\t',
      ];
      if (allowedPunctuation.includes(char)) {
        result += char;
        continue;
      }
    }
    return result;
  }
  
  cleanedReply = keepOnlySpeechFriendlyChars(cleanedReply);
  cleanedReply = cleanedReply.replace(/\s{2,}/g, ' ').trim();
  cleanedReply = cleanedReply.replace(/^\s+|\s+$/gm, '').trim();
  
  return cleanedReply;
}

/**
 * æµå¼ LLM è™•ç†ï¼ˆæ”¯æŒ Claude å’Œ OpenAIï¼‰
 * @param {string} prompt - ç”¨æˆ¶è¼¸å…¥
 * @param {Array} conversationHistory - å°è©±æ­·å²
 * @param {Object} options - é¸é …
 * @param {Function} onChunk - å›èª¿å‡½æ•¸ï¼Œæ¥æ”¶æ¯å€‹å¢é‡æ–‡å­—ç‰‡æ®µ
 * @returns {Promise<Object>} åŒ…å«å®Œæ•´å›æ‡‰å’Œæ¨™ç±¤çš„å°è±¡
 */
export async function chatWithLLMStream(prompt, conversationHistory = [], options = {}, onChunk = null) {
  try {
    await initializeClients();
    
    // ç¢ºä¿ç³»çµ±æç¤ºè©å·²è¼‰å…¥
    if (!SYSTEM_PROMPT) {
      const { loadSystemPrompt } = await import("./llm.js");
      SYSTEM_PROMPT = await loadSystemPrompt();
    }
    
    const { emotion, enableTags = true, userIdentity, userName, abortSignal } = options;
    const { messages, identityTags } = buildMessages(prompt, conversationHistory, { emotion, userIdentity, userName });
    
    const temperature = emotion === "é–‹å¿ƒ" ? 0.9 : emotion === "é›£é" ? 0.7 : 0.8;
    let fullText = "";
    let selectedTags = [];
    
    if (LLM_PROVIDER === "claude" && anthropicClient) {
      // ========== Claude API æµå¼è™•ç† ==========
      
      const systemMessages = messages
        .filter(m => m.role === "system")
        .map(m => m.content);
      const systemPrompt = systemMessages.join("\n\n");
      
      const conversationMessages = messages
        .filter(m => m.role !== "system")
        .map(m => ({
          role: m.role === "assistant" ? "assistant" : "user",
          content: typeof m.content === "string" ? m.content : JSON.stringify(m.content),
        }));
      
      const stream = await anthropicClient.messages.stream({
        model: process.env.CLAUDE_MODEL || "claude-3-5-sonnet-20241022",
        max_tokens: 300,
        temperature: temperature,
        system: systemPrompt,
        messages: conversationMessages,
        abortSignal: abortSignal, // æ”¯æŒä¸­æ­¢
      });

      for await (const event of stream) {
        // æª¢æŸ¥æ˜¯å¦è¢«ä¸­æ­¢
        if (abortSignal && abortSignal.aborted) {
          console.log("â¹ï¸  LLM æµå¼è™•ç†è¢«ä¸­æ­¢");
          throw new Error("LLM stream aborted");
        }
        
        if (event.type === "content_block_delta") {
          const delta = event.delta;
          if (delta.type === "text") {
            const textDelta = delta.text;
            fullText += textDelta;
            
            // èª¿ç”¨å›èª¿å‡½æ•¸ç™¼é€å¢é‡æ–‡å­—
            if (onChunk && typeof onChunk === "function") {
              onChunk({
                delta: textDelta,
                fullText: fullText,
                isComplete: false,
              });
            }
          }
        } else if (event.type === "content_block_stop") {
          // è™•ç†å®Œæˆ
          break;
        }
      }

      // ç²å–æœ€çµ‚å›æ‡‰ï¼ˆåŒ…å«å·¥å…·èª¿ç”¨ç­‰ï¼‰
      const finalEvent = await stream.finalMessage();
      if (finalEvent && finalEvent.content) {
        for (const block of finalEvent.content) {
          if (block.type === "tool_use" && block.name === "select_emotion_tags") {
            try {
              const args = block.input;
              selectedTags = args.tags || [];
            } catch (e) {
              console.error("âŒ è§£ææ¨™ç±¤å¤±æ•—:", e);
            }
          }
        }
      }
      
    } else if (LLM_PROVIDER === "openai" && openaiClient) {
      // ========== OpenAI API æµå¼è™•ç† ==========
      
      const stream = await openaiClient.chat.completions.create({
        model: process.env.OPENAI_MODEL || "gpt-4o-mini",
        messages: messages,
        temperature: temperature,
        max_tokens: 300,
        stream: true,
        signal: abortSignal, // æ”¯æŒä¸­æ­¢
      });

      for await (const chunk of stream) {
        // æª¢æŸ¥æ˜¯å¦è¢«ä¸­æ­¢
        if (abortSignal && abortSignal.aborted) {
          console.log("â¹ï¸  LLM æµå¼è™•ç†è¢«ä¸­æ­¢");
          throw new Error("LLM stream aborted");
        }
        
        const delta = chunk.choices[0]?.delta?.content;
        if (delta) {
          fullText += delta;
          
          // èª¿ç”¨å›èª¿å‡½æ•¸ç™¼é€å¢é‡æ–‡å­—
          if (onChunk && typeof onChunk === "function") {
            onChunk({
              delta: delta,
              fullText: fullText,
              isComplete: false,
            });
          }
        }
        
        // è™•ç†å·¥å…·èª¿ç”¨ï¼ˆOpenAIï¼‰
        if (chunk.choices[0]?.delta?.tool_calls) {
          // OpenAI æµå¼å·¥å…·èª¿ç”¨è™•ç†è¼ƒè¤‡é›œï¼Œé€™è£¡ç°¡åŒ–è™•ç†
          // å¯¦éš›ä½¿ç”¨ä¸­å¯èƒ½éœ€è¦å®Œæ•´çš„å·¥å…·èª¿ç”¨æµç¨‹
        }
      }
      
    } else {
      throw new Error("æœªé…ç½®æœ‰æ•ˆçš„ LLM æä¾›å•†ã€‚è«‹è¨­ç½® OPENAI_API_KEY æˆ– ANTHROPIC_API_KEY");
    }

    // å¦‚æœæ²’æœ‰é¸æ“‡æ¨™ç±¤ï¼Œæ ¹æ“šèº«ä»½å’Œæƒ…ç·’è‡ªå‹•æ¨è–¦
    if (selectedTags.length === 0) {
      if (identityTags.length > 0) {
        selectedTags = [...identityTags];
      }
      
      if (emotion) {
        const emotionToTags = {
          'é–‹å¿ƒ': ['excited', 'smile', 'playful'],
          'é›£é': ['warm', 'tender', 'whisper'],
          'ç”Ÿæ°£': ['thoughtful'],
          'å¹³éœ': ['flirty', 'breathy'],
        };
        if (emotionToTags[emotion]) {
          selectedTags = [...new Set([...selectedTags, ...emotionToTags[emotion]])];
        }
      }
    }
    
    // æ¸…ç†æœ€çµ‚æ–‡å­—
    const cleanedText = cleanReply(fullText);
    
    // èª¿ç”¨æœ€å¾Œä¸€æ¬¡å›èª¿ï¼ˆæ¨™è¨˜å®Œæˆï¼‰
    if (onChunk && typeof onChunk === "function") {
      onChunk({
        delta: "",
        fullText: cleanedText,
        isComplete: true,
        tags: selectedTags,
      });
    }
    
    return {
      reply: cleanedText,
      tags: selectedTags,
    };
    
  } catch (error) {
    // å¦‚æœæ˜¯ä¸­æ­¢éŒ¯èª¤ï¼Œä¸è¨˜éŒ„ç‚ºéŒ¯èª¤
    if (error.name === "AbortError" || error.message === "LLM stream aborted") {
      console.log(`â¹ï¸  LLM æµå¼è™•ç†è¢«ä¸­æ­¢`);
      throw error;
    }
    console.error(`âŒ LLM æµå¼è™•ç†å¤±æ•—:`, error);
    throw error;
  }
}

